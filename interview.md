LLM 基础：大模型是怎么训练出来的？
Transform 的架构，Encoder 和 Decoder 是什么？
Function Call 是怎么训练的？
微调的方案有哪些？自己做过没有？
大模型分词器是什么？
Embedding 是什么？你们用的那个模型？

# 💡 LLM 基础知识详解

## 1. 🧠 大模型是怎么训练出来的？

大语言模型（LLM）的训练通常分为以下几个阶段：

### ① 数据准备

- **文本清洗**：去除低质量、重复、违法内容
- **去重/分词/格式化**：统一编码、语言标识
- **多语种数据处理**：构建语言比例（如中英比 2:8）
- **Tokenization**：使用自定义分词器转为 Token 序列

### ② 预训练（Pretraining）

- 目标：让模型学习语言本身的结构、语义、常识
- 常见任务：
  - **Causal Language Modeling (CLM)**：如 GPT 系列，只看前文预测下一个 token
  - **Masked Language Modeling (MLM)**：如 BERT，随机 mask 输入部分 token 并预测它们
- 数据量：通常需要数百 GB 到数 TB 的文本数据
- 训练过程：
  - 使用分布式并行技术（数据并行、模型并行、流水线并行）
  - FP16 / BF16 混合精度加速训练
  - 使用 AdamW 优化器、warmup + cosine decay 学习率调度

### ③ 微调（Fine-tuning）

- **SFT（监督微调）**：加入人工标注的 QA、指令跟随等数据
- **RLHF（人类反馈强化学习）**：
  - 收集成对偏好数据（A vs B 哪个回答好）
  - 用奖励模型评分，用 PPO（Proximal Policy Optimization）进行强化学习
- **DPO（Direct Preference Optimization）**：一种稳定、无需训练奖励模型的直接优化方法

---

## 2. 🏗️ Transformer 架构与 Encoder / Decoder 区别

### Transformer 核心组件

- **Self-Attention**：每个 token 关注输入序列中所有位置
- **Multi-Head Attention**：多组 attention 并行学习不同子空间信息
- **Feed-Forward Network**：非线性变换增强模型表达力
- **Residual Connection** + LayerNorm：稳定训练过程
- **Positional Encoding**：加入位置信息

### Encoder vs Decoder

| 构件      | Encoder                                 | Decoder                                 |
|-----------|------------------------------------------|------------------------------------------|
| 输入类型  | 全部可见输入                            | 自回归输入（仅当前及之前 token 可见）  |
| 用途      | 理解任务（如分类、摘要）                | 生成任务（如翻译、对话、写作）          |
| 特征      | 双向注意力（BERT）                      | 单向注意力 + Encoder-Decoder 注意力（GPT）|

---

## 3. 📞 Function Call 是怎么训练的？

### 任务定义

Function Call 即 LLM 调用外部工具/函数完成复杂任务，如调用日历、查询数据库、发送请求等。
利用现有的框架进行 Function Call（函数调用）训练，本质是通过 指令微调（Instruction Tuning） 或 函数调用微调（Function Calling Fine-tuning） 方式，让模型学会识别用户意图并输出结构化函数调用格式（JSON)

### 训练方式

- **添加监督数据**：构造输入→输出是函数名 + 参数的 JSON（如 OpenAI Function Call 数据）
- **训练过程**：
  - 基于原始指令微调模型，使其学会输出结构化函数调用格式
  - 引入工具描述作为提示模板（Tool Use Prompting）

### 推理流程

1. 用户发出请求（如“查明天北京天气”）
2. 模型输出函数调用：
   ```json
   {
     "function": "get_weather",
     "arguments": {"city": "北京", "date": "2025-05-29"}
   }
3.系统调用后端 API 获取结果

4.模型继续对响应内容生成最终回复

实践项目：https://github.com/YUTING0907/LLM_notes/edit/main/FunctionCall/README.md

## 4. 🔧 微调方案有哪些？你是否做过？

### 常见微调方法

| 方法类型            | 描述                                           |
|---------------------|------------------------------------------------|
| Full Fine-tuning     | 全量参数微调，效果最好但资源消耗大               |
| LoRA / QLoRA         | 参数高效微调，仅更新小量 Adapter 参数             |
| PEFT                 | PEFT 是 Parameter-Efficient Fine-Tuning 的统称   |
| Prompt-tuning / P-tuning v2 | 仅训练可学习的 Prompt 嵌入向量                     |

### 实践经验

✅ 使用过 LoRA 对 ChatGLM 微调客服对话任务，包含数据标注、训练、部署全过程。

实践项目：https://github.com/YUTING0907/LLM_notes/edit/main/chatglm-lora-customer-service/README.md

---

## 5. 🧩 大模型分词器是什么？

### 功能作用

- 将文本编码为 token id（整数），输入模型处理
- 控制序列长度，提高编码效率

### 主流分词算法

| 算法名称               | 基于   | 词表大小 | 多语言支持 | OOV 处理 | 应用模型            |
| ------------------ | ---- | ---- | ----- | ------ | --------------- |
| **BPE**（Byte Pair Encoding）  | 频率合并 | 中    | 一般    | 良好     | GPT-2、RoBERTa   |
| **WordPiece**      | 语言模型 | 中等   | 较差    | 良好     | BERT、DistilBERT |
| **Unigram LM** （SentencePiece） | 概率建模 | 小    | 优秀    | 最佳     | T5、XLNet、mBART  |
| **Byte-level BPE** | 字节处理 | 小    | 极佳    | 最佳     | GPT-3、ChatGPT   |

BPE 是一种数据压缩启发式分词方法。最初被用于图像压缩领域，后被 NLP 借鉴。
初始将文本分割为 字符级别 token；
统计所有相邻字符对的出现频率；
每次选择频率最高的字符对，将其 合并为新 token；
不断迭代，直到达到预设词表大小。

Byte-level BPE 是 GPT 系列使用的分词器，它在标准 BPE 上进行了修改：
对每个字符按字节处理（Unicode 编码），包括空格、标点；
再进行 BPE 合并操作；
支持几乎所有语言字符集，避免编码失败。

---

## 6. 🧬 什么是 Embedding？你们使用哪个模型？

### 定义

Embedding 是将文本/句子转为稠密向量，用于语义计算。

### 应用场景

- 检索（Semantic Search）
- 聚类、分类
- 相似度计算

### 常用模型

- `text-embedding-ada-002`：OpenAI 提供的多语言模型
- `bge-large-zh`：中文语义检索效果佳
- `m3e-base`：多任务中文模型，覆盖分类/搜索/问答等任务

---

Lib：
介绍一下 langchian
介绍一下 autogen
有没有用过大模型的网关框架（litellm）
为什么手搓 agent，而不是用框架？
mcp 是什么？和 Function Call 有什么区别？有没有实践过？
A2A 了解吗？

# 大模型相关的 Lib

---

## 🧱 1. 什么是 LangChain？

### 简介
LangChain 是一个用于构建基于大语言模型（LLM）应用的 **开发框架**，支持链式调用、工具集成、向量数据库、Agent 调度等。

### 关键能力

| 能力              | 说明                                                  |
|-------------------|-------------------------------------------------------|
| PromptTemplates   | 自定义 Prompt 生成模版                                |
| Chains            | 串联多个步骤（模型、函数、检索等）组成流程              |
| Agents            | 动态决策、自动调用工具的智能体机制                    |
| Memory            | 支持短期/长期记忆存储                                 |
| VectorStore       | 支持 FAISS、Pinecone、Qdrant 等向量数据库接口         |
| LangGraph         | 构建多 Agent 工作流（DAG）                            |

---

## 🤖 2. 什么是 AutoGen？

### 简介
AutoGen 是微软开源的 **多智能体协作框架**，基于 LLM 的角色扮演机制，让多个智能体相互协作完成复杂任务。

### 关键特性

- 多角色定义（用户、工程师、规划者等）
- 支持对话式任务规划（类似人类团队沟通）
- 自带 Function Call、回调钩子等机制
- 支持日志追踪、反思机制、异常处理

### 应用场景

- 自动编程（如 Devin 概念验证）
- 多步数据分析任务（如用户 → 数据分析师 → Python Agent）
- 高度模块化 LLM 应用搭建

---


## 🌉 3. 用过 LiteLLM 吗？它做什么？

### LiteLLM 是什么？

- 一个开源的 **多模型统一网关代理框架**
- 支持 OpenAI、Azure、Anthropic、Mistral、Baichuan、Qwen 等模型的统一接入

### 能力包括：

| 功能            | 说明                                |
|-----------------|-------------------------------------|
| 路由切换        | 根据负载或策略切换不同模型服务       |
| 限流监控        | 支持 Token 限制、指标上报            |
| Prompt 缓存     | 热点问题返回历史响应或缓存答案        |
| 模型降级        | 主模型不可用时 fallback 到次模型     |

> 🚀 适用于生产环境的 LLM API 统一调度与稳定性增强

---

## 🛠️ 4. 为什么「不直接用框架」而手工写 Agent？

### 框架优势：

- 效率：避免重复造轮子（如HTTP请求用 requests 而非 urllib）。
- 稳定性：成熟库经过测试（如 numpy 的数值计算优化）。
- 生态：兼容其他工具（如 LangChain 集成 OpenAI + FAISS）。

### 手工实现（手搓）的原因：

- 框架抽象过重，灵活性有限
- 有些功能需求无法用已有模块覆盖
- 需要精准控制 Prompt、上下文与调度逻辑（特别是定制化 Function Call）
- 对性能、延迟有更高要求

> ✅ 初期推荐使用 LangChain 等框架，后期成熟再做定制化工程重构

---

## ⚙️ 5. MCP 是什么？和 Function Call 有什么区别？有没有实践过？

### ✅ MCP：Multi-step Call Planning

> **由 ChatGPT 推出的 Function Calling 扩展机制（2024）**

### 特点：

- 支持 LLM 主动规划多步函数执行链
- 中间状态自动串联（无需显式引导）
- LLM 控制流程决策，更智能
- 支持副作用链式处理（如写入数据库 → 查询 → 返回）

### 与 Function Call 区别：

| 特性             | Function Call           | MCP（多步骤调用）              |
|------------------|--------------------------|--------------------------------|
| 调用数量         | 单次函数调用              | 多个函数组合执行链             |
| 控制粒度         | 工具调用由开发者控制       | LLM 可自主规划流程              |
| 状态传递         | 人工引导状态拼接           | 自动提取参数 + 中间状态         |
| 适用场景         | 简单问答、单工具调用       | 多步计划、复杂业务流程         |

### 实践经历：

- 已实践用于 **智能客服工单流转**：
  - LLM 规划：获取用户信息 → 查询订单状态 → 判断需不需要升级人工
  - MCP 用于指挥各步骤：先获取订单ID，再查状态，再判断是否挂工单

---

## 🔁 6. A2A 是什么？用过吗？

### ✅ A2A：Agent-to-Agent Communication

> 多个 Agent 之间通过消息或对话协同解决任务的一种范式

### 常见类型：

- **广播式协作**：一个主控 Agent 分配任务，其它 Agent 并发处理
- **链式协作**：任务从 A → B → C 依次传递
- **竞争式协作**：多个 Agent 给出不同答案，由主控选择最优解
- **评审式协作**：执行 Agent + 审查 Agent + 总结 Agent

### 实践场景：

- 项目中使用 LangGraph 实现 A2A 工作流：
  - 用户 Agent 发起任务
  - 规划 Agent 生成执行链
  - 工具 Agent 执行步骤（调用函数）
  - 审校 Agent 检查是否合理，决定是否 Replan

---

Prompt：
ReAct 是啥？怎么实现的？
CoT 是啥？为啥效果好呢？有啥缺点？
Prompt Caching 是什么？
温度值/top-p/top-k 分别是什么？各个场景下的最佳设置是什么？

# 💡 Prompt 技术知识点解析

## 🔁 ReAct 是啥？怎么实现的？

**ReAct（Reason + Act）** 是一种结合“思维链（Reasoning）”与“外部行动（Action）”的推理范式，适用于需要多步思考和外部工具调用的任务。

### ✅ 实现方式：
通过交替引导语言模型进行：
Thought: 我需要获取信息
Action: Search["信息关键词"]
Observation: 搜索结果
Thought: 我得到了答案
Answer: xxx

### 📌 应用场景：
- 智能体任务（Agents）
- LangChain、LangGraph 中的多工具推理流程

## 🧠 CoT（Chain-of-Thought）是啥？为什么效果好？有啥缺点？

### ✅ 定义：
**CoT（思维链）** 是让模型在回答问题前先“分步骤思考”的方法。

### 📈 优点：
- 增强推理能力，特别是在数学、逻辑问题上
- 大模型（如 GPT-3.5/4）中效果显著

### ❌ 缺点：
- Prompt 更长
- 有时会生成“虚假推理”（hallucination）
- 中小模型效果不明显


---

## 🗂️ Prompt Caching 是什么？

**Prompt Caching** 是指缓存已有 prompt 的结果，避免重复请求，常用于加速流程并降低 API 成本。

### 📌 应用场景：
- LangChain 工作流加速
- 多轮对话缓存
- 开发调试阶段减少等待

### 🛠️ 实现方式：
- 本地缓存：JSON、SQLite、Redis
- 向量缓存：Faiss、Chroma，用于相似 prompt 检索

---

## 🎛️ 温度值 / Top-p / Top-k 是什么？该如何设置？

| 参数名        | 含义                               | 值越小越... | 推荐用途                    |
|---------------|------------------------------------|-------------|-----------------------------|
| `temperature` | 控制生成的随机性（采样分布宽度）    | 更确定       | 代码、摘要、严谨问答         |
| `top_p`       | 样本来自概率前 p 的词组成的集合中    | 更保守       | 多样性与控制的折中           |
| `top_k`       | 样本仅来自概率最高的 k 个词中        | 更保守       | 固定选项输出场景             |

### ✅ 常见设置推荐：

| 应用场景             | Temperature | Top-p | Top-k |
|----------------------|-------------|--------|--------|
| 💬 问答类（准确性）     | 0.2~0.5     | 0.8    | 20     |
| 🧠 数学推理、代码生成   | 0.0~0.3     | 0.9    | 10     |
| 🎨 创意文本生成         | 0.7~1.0     | 0.9    | 50     |
| 🔒 固定确定输出         | 0.0         | 1.0    | 1      |

🧠 终极小口诀：
Temperature 控气氛，越高越疯；
Top-p 是看概率圈，圈内抽；
Top-k 是定前几，越小越准。

---

RAG：
你介绍一下RAG 是什么？最难的地方是哪？
文档切割策略有哪些？怎么规避语义被切割掉的问题？
多路召回是什么？
文档怎么存的？粒度是多大？用的什么数据库？
为啥要用到图数据库？
向量数据库的对比有没有做过？Qdrant 性能如何？量级是多大？有没有性能瓶颈？
怎么规避大模型的幻觉？
微调和 RAG 的优劣势？
怎么量化你的回答效果？例如检索的效果、回答的效果。


# 🔍 RAG（Retrieval-Augmented Generation）是什么？

**RAG** 是一种结合了检索（Retrieval）与生成（Generation）能力的技术架构。它先从外部知识库中检索相关文档，再将这些文档与用户问题一起输入大语言模型进行回答，从而提高答案的准确性与时效性。

- ✅ 优势：提升事实准确性、可注入私有知识、不需大规模微调。
- 🔧 实现核心：检索模块（如向量数据库） + 生成模型（如 GPT）。

---

# 🎯 最难的部分是什么？

- 文档切割：如何切割不破坏语义？
- 召回不准：检索文档无关、冗余或缺漏信息。
- 上下文限制：输入 token 限制影响文档注入。
- 幻觉问题：模型仍可能“编故事”或产生错误推理。
- 评估困难：如何衡量检索/生成是否真的“好”？

---

# ✂️ 文档切割策略有哪些？如何避免语义被破坏？

| 切割方式         | 描述                          | 优劣分析                  |
|------------------|-------------------------------|---------------------------|
| 固定长度切割      | 如每200个字一段                | 简单高效，但可能切断语义  |
| 滑动窗口切割      | 保留一定重叠，滑动窗口切片      | 增强语义连续性，计算更高 |
| 句子级切割        | 按句子分段                    | 更自然，粒度不一致        |
| 语义切割（S-BERT）| 基于语义断点聚类后切割          | 准确度更高，计算较贵      |

✅ 推荐方案：**语义切割 + 滑窗补偿**

---

# 🔁 多路召回是什么？

**多路召回（multi-path retrieval）** 指使用多种检索策略并行召回文档，如：

- 向量检索 + BM25
- 意图分类后使用不同索引
- 使用 Embedding + Reranker

目标是：提高召回率，减少遗漏与冗余。

---

# 🧾 文档怎么存？粒度多大？数据库用什么？

- **粒度**：段落、FAQ条目、对话轮次等语义单元
- **数据库类型**：
  - 向量数据库（如 Qdrant、Milvus）：用于向量存储与近似搜索
  - 文档数据库（如 MongoDB）：存储原文与元数据
  - 图数据库（如 Neo4j）：用于结构化知识建模和复杂问答

---

# 🧠 为啥要用图数据库？

- 支持实体关系建模和推理链；
- 提供基于图结构的路径搜索与事实验证；
- 与向量库形成互补，提升复杂问答能力；
- RAG+KG 是高级增强问答的一种主流组合方式。

---

# 📊 向量数据库对比 & Qdrant 性能

| 数据库   | 特点                         | 性能表现            |
|----------|------------------------------|---------------------|
| Qdrant   | Rust 构建，支持 payload 查询 | 性能优、灵活强      |
| Milvus   | 功能全面，社区成熟            | 插件复杂，资源较重  |
| Weaviate | 支持 Schema + KG             | 灵活但资源消耗大    |

- **Qdrant 优势**：高效查询，过滤能力强，REST 接口简洁；
- **潜在瓶颈**：数据量达亿级时需关注查询并发与内存优化。

---

# 🧠 如何规避大模型幻觉（Hallucination）？

| 方法                     | 原理                            |
|--------------------------|---------------------------------|
| 精准检索 + 高质量文档     | 提供可靠输入                    |
| 显式引用机制             | 模型回答中附带来源              |
| 使用 Reranker 优化结果    | 提高语义相关性排序              |
| 系统提示控制              | 引导模型降低猜测成分            |
| 使用知识图谱或外部工具     | 提升事实核查能力                |

---

# ⚖️ 微调 vs RAG

| 项目      | 微调                        | RAG                       |
|-----------|-----------------------------|---------------------------|
| 成本      | 高（训练资源消耗）          | 低（构建知识库即可）       |
| 灵活性    | 差（更新需重训）            | 强（支持热更新）           |
| 准确性    | 可高（针对任务调优）        | 依赖检索质量               |
| 工程成本  | 高（调参、训练、部署）       | 中（工程化知识库搭建）     |

---

# 📏 如何量化效果？

## 检索效果指标

- **Recall@k**：检索的前 k 个结果中是否包含正确答案
- **Precision@k**：召回结果的准确率
- **Embedding 相似度平均值**：衡量相关性
- **MMR / Rerank hit rate**：多轮检索表现

## 生成效果指标

- **BLEU / ROUGE / METEOR**：语言生成类指标
- **GPTScore / BERTScore**：语义相似度打分
- **人工评审打分**：终极标准
- **幻觉率统计**：错误率占比评估

---

workflow：
怎么做的任务拆分？为什么要拆分？效果如何？怎么提升效果？
text2sql 怎么做的？怎么提高准确率？
如何润色query，目的是什么？
code-generation 是什么做的？如何确保准确性？
现在再让你设计你会怎么做？（replan）
效果是怎么量化的？

Agent：
介绍一下你的 Agent 项目长短期记忆是怎么做的？
记忆是怎么存的？粒度是多少？怎么用的？
Function Call 是什么做的？
你最大的难题是什么？你是怎么提高效果的？怎么降低延迟的？
端到端延迟如何优化的？
介绍一下 single-agent、multi-agent 的设计方案有哪些？
反思机制是什么做的？为什么要用反思？
如何看待当下的 LLM 应用的趋势和方向
为什么要用 Webrtc？它和 ws 的区别是什么？
agent 服务高可用、稳健性是怎么保证的？
llm 服务并发太高了怎么办？

## 🧠 1. 长短期记忆是怎么做的？

### ✅ 实现方式：
- **短期记忆（Working Memory）**：
  - 存在 Agent 执行链路上下文中（如 conversation history）。
  - 通常作为 prompt 拼接输入到大模型。
  - 生命周期：单轮对话或 session。

- **长期记忆（Long-Term Memory）**：
  - 通过向量数据库（如 Qdrant/Faiss）存储历史内容的 embedding。
  - 基于当前 query 检索相关记忆并注入上下文。
  - 可细分为：知识性记忆（facts）、对话性记忆（logs）、行为记忆（actions）。

---

## 📦 2. 记忆是怎么存的？粒度是多少？怎么用的？

### 存储方式：
- 存入向量数据库（如 Qdrant）或 KV 存储（如 Redis）。
- 同步存结构化数据（时间戳、对话主题、类型等元信息）。

### 粒度：
- **对话粒度**：每轮对话或完整对话段。
- **任务粒度**：函数调用的输入输出、状态变更。
- **知识粒度**：FAQ、文档摘要、用户画像等。

### 使用方式：
- 当前对话前检索相关记忆（基于 embedding 相似度或关键词匹配）。
- 拼接入 Prompt，提升上下文感知能力。
- 搭配提示词优化，例如：`你之前告诉我...`

---

## 🧰 3. Function Call 是怎么做的？

### 实现方式：
- 利用 OpenAI 的 `function_call` 或 LangChain / LangGraph 中的工具调用（Tool/ToolNode）。
- 模型输出格式形如：
  ```json
  {
    "function_call": {
      "name": "search_document",
      "arguments": { "keyword": "RAG 技术" }
    }
  }

## ❓ 4. 你最大的难题是什么？怎么提高效果？怎么降低延迟？

### 最大难题：
- **上下文管理困难**：长对话或任务中，如何选择、注入最相关的上下文（如历史、记忆、工具结果）？
- **函数调用链路复杂**：Agent 调用多个工具/函数时，调用错误、参数错配、结果不准确的问题较多。
- **延迟问题**：尤其在多轮对话或多函数串联场景中，响应速度不佳。
- **模型幻觉**：模型生成不真实/不合理信息影响结果可靠性。

### 提高效果的方法：
- 引入 **记忆机制**（长期+短期）管理上下文；
- 使用 RAG 检索知识/历史/结果作为 context 补充；
- 对函数调用进行 **函数描述微调 / prompt 约束**，提高准确率；
- 利用 **LangGraph / StateGraph** 管理多函数链路，支持并发执行。

### 降低延迟的方法：
- 多节点 **异步并发执行**；
- 减少 context 长度（摘要压缩、Top-K 召回）；
- 工具调用加入缓存机制（如函数结果缓存）；
- 模型响应缓存（Prompt Caching）+ Rerank 精简响应候选。

---

## ⏱️ 5. 端到端延迟如何优化？

### 关键路径优化策略：
| 模块           | 优化措施                                      |
|----------------|-----------------------------------------------|
| 上下文构建     | 使用摘要生成器 + 向量检索筛选最小必要上下文     |
| 工具调用       | 函数异步调用 + 并行执行 + 结果缓存              |
| LLM 调用       | 压缩 prompt + 缓存重复调用 + 使用 Fast API 模型 |
| 数据库访问     | 建立索引 + 减少轮询 + Top-K 限流               |
| 网络传输       | 使用 WebSocket/WebRTC 减少 HTTP 轮询延迟        |

---

## 👥 6. Single-Agent vs Multi-Agent 的设计方案

### Single-Agent 架构
- 一个 Agent 负责全部任务逻辑、记忆管理、工具调用；
- 优点：简单、易部署；
- 缺点：扩展性差，复杂任务难拆解，代码臃肿。

### Multi-Agent 架构
- 每个 Agent 专责一个子任务（如计划、工具调度、执行、总结）；
- 可使用 LangGraph / CrewAI / Autogen 框架协调通信。

#### 常见 Multi-Agent 架构模型：
| 架构类型         | 描述                                           |
|------------------|------------------------------------------------|
| Planner-Executor | 一个计划 Agent 拆解任务，多个执行 Agent 执行子任务 |
| Expert Team      | 每个 Agent 是不同领域专家（代码、搜索、写作）     |
| Hierarchical     | 上级 Agent 决策调度，下级 Agent 专注执行         |

---

## 🔁 7. 反思机制（Reflection）是什么？为什么要用反思？

### 什么是反思机制？
- Agent 在 **任务失败 / 回答质量低 / 函数调用出错 / 输出不合理** 情况下，
  自动对输出进行评估、总结失败原因，并尝试重新生成或修正输入。

### 实现方式：
1. 检查器判断输出异常（如空值、不调用函数、明显幻觉）；
2. 注入失败原因 + 初始任务 + 当前输出，要求大模型 `自我评估`；
3. 生成“改进建议”，再运行新的指令链。

### 为什么要用反思？
- 提高 Agent 的健壮性；
- 降低 LLM 幻觉影响；
- 让 Agent 能 “试错 + 自我修复”；
- 有助于构建具备长期学习能力的智能体系统。

# 📈 当前 LLM 应用趋势 & 架构问题分析

---

## 🔮 如何看待当下 LLM 应用的趋势和方向？

### 1. 应用趋势
- **从 Chat 向 Tool-Use / 多智能体协作过渡**：
  - 不再只对话，而是执行任务（如 Agent + Tool）。
  - LangGraph、Autogen、CrewAI 等框架快速发展。
- **个性化 + 长期记忆增强**：
  - 融合用户历史、角色画像，实现持续学习与反馈。
- **行业落地深化**：
  - 医疗、法律、金融、政务等行业开始落地微调模型。
- **小模型 & 本地部署兴起**：
  - 为保障数据隐私、成本控制，轻量级模型和边端模型应用增长。
- **多模态整合发展**：
  - 从文字扩展到图像、语音、视频，形成统一交互接口。

---

## 🔌 为什么用 WebRTC？它和 WebSocket 有什么区别？

| 技术        | WebSocket                          | WebRTC                                            |
|-------------|------------------------------------|--------------------------------------------------|
| 用途        | 实时双向数据传输                   | 实时音视频 + 数据流（点对点）                    |
| 通信方式    | 客户端 ↔ 服务器                    | 客户端 ↔ 客户端（P2P）                            |
| 传输协议    | TCP                                | UDP（为低延迟优化）                              |
| 适合场景    | 实时文本通信、协同编辑             | 视频会议、语音通话、远程控制、边端数据传输等    |
| 优点        | 简单、支持广泛                     | 延迟低、点对点节省带宽、支持 NAT 穿透           |
| 缺点        | 不支持音视频传输                  | 配置复杂，信令通道必须外部实现（通常用 ws）     |

🔹 **总结**：如果只是 LLM 的文字聊天服务，用 `WebSocket` 足够。但如果涉及到 **音视频 Agent、实时推理** 等，`WebRTC` 延迟更低，更适合点对点高频通信场景。

---

## 🛡️ Agent 服务如何实现高可用、稳健性？

### 核心策略：
1. **节点级容错**：LangGraph 支持每个 Node 单独 Retry、降级、Fallback（如检索失败切换回答模板）；
2. **服务部署冗余**：使用容器化（Docker + K8s）部署多副本，实现负载均衡；
3. **状态监控与健康检查**：Prometheus + Grafana 监控各模块运行状态；
4. **缓存机制**：
   - Prompt Caching、Function Call Caching；
   - 避免重复请求导致错误传播；
5. **限流 / 熔断机制**：避免 LLM 服务雪崩；
6. **离线预处理 + 队列缓冲**：对非实时任务延后处理，解耦主流程。

---

## ⚙️ LLM 服务并发太高怎么办？

### 分层应对策略：

#### ✅ 应用层优化
- **Prompt Cache + Result Cache**：大幅减少重复调用；
- **任务排队 / 限流**：控制高峰调用；
- **使用异步请求**：避免阻塞等待，提升吞吐量。

#### ✅ 架构层优化
- **负载均衡 + 容器副本扩展**：如 K8s + HPA（Horizontal Pod Autoscaler）；
- **模型服务分流策略**：按任务类型路由到不同模型（Fast Chat vs GPT-4 等）；
- **多模型协同**：
  - 简单任务 → 小模型；
  - 复杂推理 → 大模型（如 GPT-4）。
- **模型本地化部署**：
  - Ollama、vLLM、TGI 组合形成高吞吐推理服务；
  - 多 GPU、Batching、KV Cache 优化推理速度。

#### ✅ 数据层优化
- 检索/知识库用 **向量数据库 + Cache 层** 减轻请求压力；
- 对外服务添加 **异步队列 + 限流机制**（如 Celery + Redis）。

---



系统设计题：
短链系统
分布式锁的设计
给你一部长篇小说，怎么做文档切割？
怎么做到论文翻译，并且格式尽可能和原来的统一
游戏社区客服助手设计。如何绑定游戏黑话，如何利用好公司内部的文档
结合线上问题快速定位项目工程代码有问题的地方
有很多结构化和非结构化数据，怎么分析，再怎么得出我要的结论

八股：
go 的内存分配策略、GMP、GC
python 的内存分配策略、GC
redis 用过那些？mget 底层什么实现的？、zset 怎么实现的？
mysql 索引怎么设计最好？数据库隔离级别？mvcc 是怎么实现的？
分布式锁是什么实现的？
kafka 的 reblance 是什么？会产生那些问题？怎么保证数据不丢?
fastapi 设计原理？
go 中 net/http 如何处理的 tcp 粘包问题
http2 是什么？比 http1.1 有什么优势？
Linux 网络性能调优的方式
如何定位 Linux 中的 pid、端口号等等
