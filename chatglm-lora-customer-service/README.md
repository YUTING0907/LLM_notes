
# ChatGLM LoRA å®¢æœå¯¹è¯å¾®è°ƒé¡¹ç›®

æœ¬é¡¹ç›®åŸºäº ChatGLM2 + LoRA å®ç°å®¢æœå¯¹è¯çš„å¾®è°ƒä¸éƒ¨ç½²ï¼Œæ”¯æŒæ•°æ®æ ‡æ³¨ â†’ LoRA å¾®è°ƒ â†’ æ¨ç†éƒ¨ç½²å…¨æµç¨‹ã€‚

---

## ğŸ”§ é¡¹ç›®ç»“æ„

```
chatglm-lora-customer-service/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ train.json               # å¾®è°ƒè®­ç»ƒæ•°æ®ï¼ˆæ ¼å¼è§ä¸‹ï¼‰
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dataset.py              # æ•°æ®åŠ è½½ä¸é¢„å¤„ç†
â”‚   â”œâ”€â”€ modeling_chatglm.py     # ChatGLM æ¨¡å‹åŠ è½½ï¼ˆå¼•ç”¨å®˜æ–¹æˆ– HuggingFaceï¼‰
â”‚   â”œâ”€â”€ train.py                # LoRA å¾®è°ƒè®­ç»ƒè„šæœ¬
â”‚   â””â”€â”€ infer.py                # æ¨ç†è„šæœ¬ï¼ˆå•è½®/å¤šè½®å¯¹è¯ï¼‰
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ convert_lora.py         # åˆå¹¶/ä¿å­˜ LoRA å‚æ•°åˆ°åŸæ¨¡å‹
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## å¿«é€Ÿå¼€å§‹

```bash
# 1. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 2. å¼€å§‹è®­ç»ƒ
python src/train.py

# 3. æ¨ç†éªŒè¯
python src/infer.py

å•è½®æ¨ç†ï¼š
python src/infer.py --mode single --query "ä½ ä»¬çš„é€€è´§æ”¿ç­–æ˜¯æ€æ ·çš„ï¼Ÿ"

å¤šè½®å¯¹è¯ï¼š
python src/infer.py --mode interactive

# 4.ç”¨äºå°† LoRA å¾®è°ƒåçš„å‚æ•°åˆå¹¶åˆ°åŸå§‹ ChatGLM æ¨¡å‹ä¸­å¹¶ä¿å­˜ä¸ºå•ä¸€æƒé‡ï¼š

python scripts/convert_lora.py \
    --base_model THUDM/chatglm2-6b \
    --lora_model ./output/lora \
    --output_dir ./output/chatglm2-lora-merged
```
è¿è¡Œåä¼šåœ¨ output_dir ä¸­ä¿å­˜åˆå¹¶äº† LoRA çš„å®Œæ•´æ¨¡å‹ï¼Œå¯ç›´æ¥ä½¿ç”¨ AutoModel.from_pretrained() åŠ è½½ï¼Œæ— éœ€å†åŠ è½½ LoRA å‚æ•°ã€‚


